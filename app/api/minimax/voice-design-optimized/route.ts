import { NextRequest, NextResponse } from 'next/server'

export async function POST(request: NextRequest) {
  try {
    const { voiceDesignData } = await request.json()

    if (!voiceDesignData || typeof voiceDesignData !== 'object') {
      return NextResponse.json({
        success: false,
        error: 'ç¼ºå°‘éŸ³è‰²è®¾è®¡æ•°æ®'
      }, { status: 400 })
    }

    const voiceDesigns: Record<string, any> = {}
    const preGeneratedAudios: Record<string, string> = {}

    // ä¸ºæ¯ä¸ªè¯´è¯è€…è®¾è®¡éŸ³è‰²å¹¶ç”Ÿæˆè¯•å¬éŸ³é¢‘
    for (const [speaker, data] of Object.entries(voiceDesignData)) {
      const { voicePrompt, previewText } = data as { voicePrompt: string; previewText: string }

      try {
        // ä¼˜åŒ–æ–¹æ¡ˆï¼šæ ¹æ®MiniMaxå®˜æ–¹æ–‡æ¡£ï¼Œä½¿ç”¨éŸ³è‰²è®¾è®¡APIä½†å°†å¯¹è¯å†…å®¹ä½œä¸ºè¯•å¬æ–‡æœ¬
        // è¿™æ ·å¯ä»¥åœ¨è®¾è®¡éŸ³è‰²çš„åŒæ—¶ç”Ÿæˆå®Œæ•´çš„å¯¹è¯éŸ³é¢‘ï¼Œåªæ”¶å–å­—ç¬¦è´¹ç”¨
        const designResponse = await fetch('https://api.minimax.chat/v1/voice_generation', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.MINIMAX_API_KEY}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'speech-01',
            voice_setting: {
              voice_id: speaker.includes('ä¸»æŒäºº') ? 'male_qn_qingse' : 'female_tianmei',
              speed: 1.0,
              vol: 1.0,
              pitch: 0
            },
            text: previewText, // å…³é”®ï¼šä½¿ç”¨å®Œæ•´å¯¹è¯å†…å®¹ä½œä¸ºè¯•å¬æ–‡æœ¬
            audio_setting: {
              audio_sample_rate: 32000,
              bitrate: 128000,
              format: 'mp3'
            },
            pronunciation_dict: {
              tone: voicePrompt // éŸ³è‰²æè¿°
            }
          }),
        })

        if (!designResponse.ok) {
          throw new Error(`MiniMax API error: ${designResponse.status}`)
        }

        const designResult = await designResponse.json()

        if (designResult.base_resp?.status_code === 0) {
          // æˆåŠŸï¼šä¿å­˜éŸ³è‰²ä¿¡æ¯å’Œé¢„ç”Ÿæˆçš„éŸ³é¢‘
          voiceDesigns[speaker] = {
            voiceId: designResult.voice_id || (speaker.includes('ä¸»æŒäºº') ? 'male_qn_qingse' : 'female_tianmei'),
            voicePrompt: voicePrompt,
            audioSampleRate: 32000,
            bitrate: 128000,
            isOptimized: true, // æ ‡è®°ä¸ºä¼˜åŒ–æ–¹æ¡ˆ
            characterCount: previewText.length // è®°å½•å­—ç¬¦æ•°ç”¨äºæˆæœ¬è®¡ç®—
          }

          // ä¿å­˜é¢„ç”Ÿæˆçš„éŸ³é¢‘URLï¼ˆè¿™æ˜¯å…³é”®ï¼šé€šè¿‡è¯•å¬æ–‡æœ¬ç”Ÿæˆçš„å®Œæ•´å¯¹è¯éŸ³é¢‘ï¼‰
          if (designResult.audio_url) {
            preGeneratedAudios[speaker] = designResult.audio_url
            console.log(`âœ… ${speaker} éŸ³é¢‘ç”ŸæˆæˆåŠŸï¼Œå­—ç¬¦æ•°: ${previewText.length}`)
          } else {
            throw new Error(`${speaker} éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼šæœªè¿”å›éŸ³é¢‘URL`)
          }
        } else {
          // ä¸è¿›è¡Œé™çº§å¤„ç†ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
          const errorMsg = designResult.base_resp?.status_msg || 'æœªçŸ¥é”™è¯¯'
          throw new Error(`${speaker} éŸ³è‰²è®¾è®¡å¤±è´¥: ${errorMsg}`)
        }
      } catch (error) {
        console.error(`å¤„ç†è¯´è¯è€… ${speaker} æ—¶å‡ºé”™:`, error)
        // ä¸è¿›è¡Œé™çº§å¤„ç†ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
        throw new Error(`å¤„ç†è¯´è¯è€… ${speaker} æ—¶å‡ºé”™: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`)
      }
    }

    // éªŒè¯æ˜¯å¦æ‰€æœ‰è§’è‰²éƒ½æˆåŠŸç”Ÿæˆäº†éŸ³é¢‘
    if (Object.keys(preGeneratedAudios).length === 0) {
      throw new Error('æ‰€æœ‰è§’è‰²çš„éŸ³é¢‘ç”Ÿæˆéƒ½å¤±è´¥äº†')
    }

    console.log(`ğŸ™ï¸ éŸ³è‰²è®¾è®¡ä¼˜åŒ–æ–¹æ¡ˆå®Œæˆ: ${Object.keys(preGeneratedAudios).length}ä¸ªè§’è‰²éŸ³é¢‘ç”ŸæˆæˆåŠŸ`)

    return NextResponse.json({
      success: true,
      data: {
        voiceDesigns,
        preGeneratedAudios
      }
    })

  } catch (error) {
    console.error('éŸ³è‰²è®¾è®¡ä¼˜åŒ–ç‰ˆæœ¬å¤±è´¥:', error)
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'éŸ³è‰²è®¾è®¡å¤±è´¥'
    }, { status: 500 })
  }
}
