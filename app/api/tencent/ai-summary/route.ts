import { NextRequest, NextResponse } from 'next/server'
import { getServerSession } from 'next-auth'
import { authOptions } from '@/lib/auth'
import OpenAI from 'openai'

// ä½¿ç”¨OpenAIå…¼å®¹çš„APIï¼ˆå¯ä»¥æ˜¯ä»»ä½•å…¼å®¹çš„AIæœåŠ¡ï¼‰
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
  baseURL: process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1',
})

export async function POST(request: NextRequest) {
  try {
    // éªŒè¯ç”¨æˆ·ç™»å½•çŠ¶æ€
    const session = await getServerSession(authOptions)
    if (!session?.user?.email) {
      return NextResponse.json(
        { error: 'è¯·å…ˆç™»å½•' },
        { status: 401 }
      )
    }

    const { transcriptText, segments, language = 'zh' } = await request.json()

    if (!transcriptText) {
      return NextResponse.json(
        { error: 'è½¬å½•æ–‡æœ¬ä¸èƒ½ä¸ºç©º' },
        { status: 400 }
      )
    }

    // åªæ”¯æŒä¸­æ–‡æ€»ç»“
    if (language !== 'zh') {
      return NextResponse.json(
        { error: 'å½“å‰ä»…æ”¯æŒä¸­æ–‡å†…å®¹æ€»ç»“' },
        { status: 400 }
      )
    }

    // æž„å»ºAIæ€»ç»“çš„æç¤ºè¯
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éŸ³é¢‘å†…å®¹æ€»ç»“ä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„éŸ³é¢‘è½¬å½•æ–‡æœ¬ï¼Œç”Ÿæˆä¸€ä¸ªç»“æž„åŒ–çš„æ€»ç»“æŠ¥å‘Šã€‚

è¦æ±‚ï¼š
1. æå–æ ¸å¿ƒè¦ç‚¹å’Œå…³é”®ä¿¡æ¯
2. æŒ‰ç…§é€»è¾‘é¡ºåºç»„ç»‡å†…å®¹
3. ä¿ç•™é‡è¦çš„æ—¶é—´èŠ‚ç‚¹ä¿¡æ¯
4. ä½¿ç”¨æ¸…æ™°çš„æ ‡é¢˜å’Œæ®µè½ç»“æž„
5. çªå‡ºé‡è¦è§‚ç‚¹å’Œç»“è®º
6. å¦‚æžœæœ‰å¤šä¸ªè¯´è¯äººï¼Œè¯·åŒºåˆ†ä¸åŒè¯´è¯äººçš„è§‚ç‚¹

è¾“å‡ºæ ¼å¼ï¼š
# éŸ³é¢‘å†…å®¹æ€»ç»“

## ðŸ“‹ åŸºæœ¬ä¿¡æ¯
- æ€»æ—¶é•¿ï¼š[æ—¶é•¿]
- ä¸»è¦è¯é¢˜ï¼š[è¯é¢˜]
- å‚ä¸Žäººæ•°ï¼š[äººæ•°]

## ðŸŽ¯ æ ¸å¿ƒè¦ç‚¹
[åˆ—å‡º3-5ä¸ªæ ¸å¿ƒè¦ç‚¹]

## ðŸ“ è¯¦ç»†å†…å®¹
[æŒ‰æ—¶é—´é¡ºåºæˆ–ä¸»é¢˜åˆ†ç±»æ•´ç†å†…å®¹]

## ðŸ’¡ é‡è¦è§‚ç‚¹
[æå–é‡è¦è§‚ç‚¹å’Œç»“è®º]

## ðŸ”— å…³é”®æ—¶é—´èŠ‚ç‚¹
[å¦‚æžœæœ‰é‡è¦æ—¶é—´èŠ‚ç‚¹ï¼Œè¯·åˆ—å‡º]

è¯·ç¡®ä¿æ€»ç»“å‡†ç¡®ã€ç®€æ´ã€æœ‰æ¡ç†ã€‚`

    const userPrompt = `è¯·æ€»ç»“ä»¥ä¸‹éŸ³é¢‘è½¬å½•å†…å®¹ï¼š

è½¬å½•æ–‡æœ¬ï¼š
${transcriptText}

${segments && segments.length > 0 ? `
æ—¶é—´æˆ³ä¿¡æ¯ï¼š
${segments.map((seg: any) => `[${formatTime(seg.startTime)}-${formatTime(seg.endTime)}] ${seg.text}`).join('\n')}
` : ''}

è¯·ç”Ÿæˆç»“æž„åŒ–çš„æ€»ç»“æŠ¥å‘Šã€‚`

    console.log('å¼€å§‹AIæ€»ç»“ï¼Œæ–‡æœ¬é•¿åº¦:', transcriptText.length)

    // è°ƒç”¨AIç”Ÿæˆæ€»ç»“
    const completion = await openai.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.3,
      max_tokens: 2000,
    })

    const summary = completion.choices[0]?.message?.content

    if (!summary) {
      throw new Error('AIæ€»ç»“ç”Ÿæˆå¤±è´¥')
    }

    console.log('AIæ€»ç»“ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦:', summary.length)

    return NextResponse.json({
      success: true,
      message: 'AIæ€»ç»“ç”ŸæˆæˆåŠŸ',
      data: {
        summary,
        originalLength: transcriptText.length,
        summaryLength: summary.length,
        compressionRatio: Math.round((1 - summary.length / transcriptText.length) * 100)
      }
    })

  } catch (error) {
    console.error('AIæ€»ç»“é”™è¯¯:', error)
    return NextResponse.json(
      { 
        error: 'AIæ€»ç»“ç”Ÿæˆå¤±è´¥',
        details: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      },
      { status: 500 }
    )
  }
}

// è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–æ—¶é—´
function formatTime(seconds: number): string {
  const hours = Math.floor(seconds / 3600)
  const minutes = Math.floor((seconds % 3600) / 60)
  const secs = Math.floor(seconds % 60)
  
  if (hours > 0) {
    return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  } else {
    return `${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }
}
